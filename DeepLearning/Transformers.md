Transformers


# [Blogs]
+ The Illustrated Transformer, https://jalammar.github.io/illustrated-transformer/
+ Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention),https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
+ Self-Attentionå’ŒTransformer, https://luweikxy.gitbook.io/machine-learning-notes/self-attention-and-transformer
+ A Complete Learning Path To Transformers (With Guide To 23 Architectures), https://analyticsindiamag.com/a-complete-learning-path-to-transformers/
+ The Essential Guide to Transformers, the Key to Modern SOTA AI, https://www.kdnuggets.com/2021/06/essential-guide-transformers-key-modern-sota-ai.html
+ How Transformers work in deep learning and NLP: an intuitive introduction, https://theaisummer.com/transformer/
+ Comprehensive Guide To Transformers, https://analyticsindiamag.com/a-comprehensive-guide-to-transformers/
+ Zero-Shot Controlle Generation with Encoder-Decoder Transformers, https://www.amazon.science/latest-news/controlling-language-generation-models-without-training-data?utm_content=buffer9ee31&utm_medium=social&utm_source=linkedin.com&utm_campaign=buffer
+ This course will teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem â€” ðŸ¤— Transformers, ðŸ¤— Datasets, ðŸ¤— Tokenizers, and ðŸ¤— Accelerate â€” as well as the Hugging Face Hub. Itâ€™s completely free and without ads., https://huggingface.co/course/chapter1
+ 



# [Papers-Surveys]
+ A Survey of Transformers, Tianyang Lin, Yuxin Wang, Xiangyang Liu, Xipeng Qiu, https://arxiv.org/abs/2106.04554
+ TransformerFusion: Monocular RGB Scene Reconstruction using Transformers, https://arxiv.org/abs/2107.02191
+ BumbleBee: A Transformer for Music, https://arxiv.org/abs/2107.03443
+ ViTGAN: Training GANs with Vision Transformers, https://arxiv.org/abs/2107.04589
+ Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation, https://github.com/NVIDIA-Merlin/publications/tree/main/2021_acm_recsys_transformers4rec
+ 


# [Papers]


# [Codes]
